{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344af15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "comments_path = 'ASM_PZ2_podaci_2122/reddit2008/comments_2008_asm/csv-{}.csv'\n",
    "comments_list = []\n",
    "for i in range(0, 12):\n",
    "    comments_list.append(pd.read_csv(comments_path.format(i)))\n",
    "\n",
    "comments_dtypes = {\n",
    "    \"id\": object,\n",
    "    \"author\": object,\n",
    "    \"link_id\": object,\n",
    "    \"parent_id\": object,\n",
    "    \"created_utc\": int,\n",
    "    \"subreddit\": object,\n",
    "    \"subreddit_id\": object,\n",
    "    \"score\": int,\n",
    "    \"distinguished\": object,\n",
    "    \"gilded\": int,\n",
    "    \"controversiality\": int\n",
    "}\n",
    "#comments_data = comments_data.astype(comments_dtypes)\n",
    "    \n",
    "comments_data = pd.concat(comments_list)\n",
    "comments_list = []\n",
    "comments_data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(comments_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97894e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_path = 'ASM_PZ2_podaci_2122/reddit2008/submissions_2008_asm/csv-{}.csv'\n",
    "submissions_list = []\n",
    "for i in range(0, 12):\n",
    "    submissions_list.append(pd.read_csv(submissions_path.format(i)))\n",
    "\n",
    "submissions_dtypes = {\n",
    "    \"id\": object,\n",
    "    \"url\": object,\n",
    "    \"permalink\": object,\n",
    "    \"author\": object,\n",
    "    \"created_utc\": int,\n",
    "    \"subreddit\": object,\n",
    "    \"subreddit_id\": object,\n",
    "    \"num_comments\": int,\n",
    "    \"score\": int,\n",
    "    \"over_18\": bool,\n",
    "    \"distinguished\": object,\n",
    "    \"domain\": object,\n",
    "    \"stickied\": bool,\n",
    "    \"locked\": bool,\n",
    "    \"hide_score\": bool\n",
    "}\n",
    "#submissions_data = submissions_data.astype(submissions_dtypes)\n",
    "    \n",
    "submissions_data = pd.concat(submissions_list)\n",
    "submissions_list = []\n",
    "submissions_data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(submissions_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d28b6",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b001e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comments_data['id'].isnull().values.any())\n",
    "print(comments_data['id'].is_unique)\n",
    "\n",
    "print(submissions_data['id'].isnull().values.any())\n",
    "print(submissions_data['id'].is_unique)\n",
    "\n",
    "comments_null_id = comments_data[comments_data['id'].isnull()]\n",
    "print(\"\\n\", comments_null_id)\n",
    "\n",
    "print(\"\\n\", comments_data.iloc[6422486:6422489, :])\n",
    "\n",
    "comments_data.loc[comments_data['id'].isnull(), 'id'] = \"nan\"\n",
    "\n",
    "print(\"\\nAfter id null fix:\\n\", comments_data.iloc[6422486:6422489, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baecf069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unnamed column COMMENTS\n",
    "print(comments_data.columns)\n",
    "print(comments_data[\"Unnamed: 0\"])\n",
    "\n",
    "comments_data = comments_data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(\"\\n\", comments_data.columns)\n",
    "\n",
    "# Unnamed column SUBMISSIONS\n",
    "print(\"\\n\", submissions_data.columns)\n",
    "print(submissions_data[\"Unnamed: 0\"])\n",
    "\n",
    "submissions_data = submissions_data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(\"\\n\", submissions_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d49ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments_contr_not_zero = comments_data[comments_data['controversiality'] != 0]\n",
    "print(\"\\n\", comments_contr_not_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb41aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null columns - COMMENTS\n",
    "nan_values = comments_data.isna()\n",
    "nan_columns = nan_values.any()\n",
    "columns_with_nan = comments_data.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85429d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments_dis_not_null = comments_data[comments_data['distinguished'].isnull() == False]\n",
    "print(\"\\n\", comments_dis_not_null.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null columns - SUBMISSIONS\n",
    "nan_values = submissions_data.isna()\n",
    "nan_columns = nan_values.any()\n",
    "columns_with_nan = submissions_data.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_dis_not_null = submissions_data[submissions_data['distinguished'].isnull() == False]\n",
    "print(\"\\n\", submissions_dis_not_null.shape)\n",
    "\n",
    "submissions_domain_not_null = submissions_data[submissions_data['domain'].isnull() == True]\n",
    "print(\"\\n\", submissions_domain_not_null.shape)\n",
    "#print(\"\\n\", submissions_domain_not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types check\n",
    "print(comments_data.dtypes, \"\\n\")\n",
    "print(submissions_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ef835",
   "metadata": {},
   "source": [
    "# Statistička obrada podataka (3.4.1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44149fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Koliko postoji različitih sabredita koji se pojavljuju u posmatranom periodu? Koji su najvažniji po broju korisnika, a koji po broju komentara? \n",
    "\n",
    "submissions_subreddit_columns = submissions_data.loc[:,'subreddit' : 'subreddit_id']\n",
    "submissions_subreddit_columns = submissions_subreddit_columns.drop_duplicates()\n",
    "print(\"SUBMISSIONS Subreddits:\\n\", submissions_subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "comments_subreddit_columns = comments_data.loc[:, 'subreddit' : 'subreddit_id']\n",
    "comments_subreddit_columns = comments_subreddit_columns.drop_duplicates()\n",
    "print(\"COMMENTS Subreddits:\\n\", comments_subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "subreddit_columns = pd.concat([submissions_subreddit_columns, comments_subreddit_columns])\n",
    "print(\"ALL Subreddits:\\n\", subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "subreddit_columns = subreddit_columns.drop_duplicates()\n",
    "print(\"UNIQUE Subreddit pairs:\\n\", subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "# check for nonuniqueness (subreddits, subreddit IDs)\n",
    "print(\"\\nCHECK FOR NONUNIQUENESS\\n\")\n",
    "print(\"submissions_data subreddit_id - is unique: \", submissions_subreddit_columns['subreddit_id'].is_unique)\n",
    "print(\"comments_data subreddit_id - is unique: \", comments_subreddit_columns['subreddit_id'].is_unique)\n",
    "print(\"Column subreddit - is unique: \", subreddit_columns['subreddit'].is_unique)\n",
    "print(\"Column subreddit_id - is unique: \", subreddit_columns['subreddit_id'].is_unique, \"\\n\")\n",
    "\n",
    "data_grouped = subreddit_columns[['subreddit', 'subreddit_id']].groupby('subreddit_id')\n",
    "\n",
    "data_aggregated = data_grouped['subreddit_id'].agg(np.size)\n",
    "#print(data_aggregated, \"\\n\")\n",
    "\n",
    "data_nonunique = data_aggregated[data_aggregated > 1]\n",
    "print(data_nonunique, \"\\n\")\n",
    "\n",
    "target_match_list = data_nonunique.keys()[:]\n",
    "#print(\"Nonunique IDs:\", target_match_list, \"\\n\")\n",
    "\n",
    "data_target = subreddit_columns[subreddit_columns['subreddit_id'].isin(target_match_list)]\n",
    "print(data_target, \"\\n\")\n",
    "\n",
    "print(\"COMMENTS data rows with target_match IDs:\\n\")\n",
    "comments_target_rows = comments_data[comments_data['subreddit_id'].isin(target_match_list)]\n",
    "comments_target_rows = comments_target_rows.drop_duplicates('subreddit_id')\n",
    "print(comments_target_rows, \"\\n\")\n",
    "\n",
    "print(\"SUBMISSIONS data rows with target_match IDs:\\n\")\n",
    "submissions_target_rows = submissions_data[submissions_data['subreddit_id'].isin(target_match_list)]\n",
    "submissions_target_rows = submissions_target_rows.drop_duplicates('subreddit_id')\n",
    "print(submissions_target_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d39e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Before:\\n\", subreddit_columns, \"\\n\")\n",
    "unique_subreddits_1 = subreddit_columns[~((subreddit_columns['subreddit'] == '_Descary') & (subreddit_columns['subreddit_id'] == 't5_2qj0s'))]\n",
    "unique_subreddits = unique_subreddits_1[~((unique_subreddits_1['subreddit'] == '__Journalism') & (unique_subreddits_1['subreddit_id'] == 't5_2qhyl'))]\n",
    "print(\"After:\\n\", unique_subreddits)\n",
    "\n",
    "# Q: Koliko postoji različitih sabredita koji se pojavljuju u posmatranom periodu? \n",
    "# ANSWER: 5032\n",
    "\n",
    "# Changing subreddit (with same IDs) names from _Name to Name ##### TREBALO BI PROMENITI I permalink\n",
    "submissions_data.loc[submissions_data['subreddit_id'] == 't5_2qj0s', 'subreddit'] = 'Descary'\n",
    "submissions_data.loc[submissions_data['subreddit_id'] == 't5_2qhyl', 'subreddit'] = 'Journalism'\n",
    "\n",
    "submissions_rows = submissions_data[submissions_data['subreddit_id'].isin(target_match_list)]\n",
    "submissions_rows = submissions_rows.drop_duplicates('subreddit_id')\n",
    "print(submissions_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5543d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"SUBREDDIT WITH MAX NUMBER OF COMMENTS:\\n\")\n",
    "submissions_num_comments = submissions_data.groupby([\"subreddit\",\"subreddit_id\"]).num_comments.sum().reset_index()\n",
    "print(\"Subreddits num_comments:\\n\", submissions_num_comments, \"\\n\")\n",
    "\n",
    "max_num_comments = submissions_num_comments['num_comments'].idxmax()\n",
    "max_num_comments_row = submissions_num_comments.iloc[max_num_comments]\n",
    "print(\"Subreddits with MAX num of comments:\\n\", max_num_comments_row, \"\\n\")\n",
    "\n",
    "max_num_comments_10_rows = submissions_num_comments.nlargest(10, 'num_comments')\n",
    "print(\"First 10 subreddits with MAX num of comments:\\n\", max_num_comments_10_rows, \"\\n\")\n",
    "\n",
    "# Q: Koji su najvažniji po broju korisnika, a koji po broju komentara?\n",
    "# A: Po broju komentara: reddit.com (1768764), politics(1059618), programming(421137), ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUBREDDIT WITH MAX NUMBER OF USERS:\\n\")\n",
    "submissions_authors = submissions_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Subreddits authors:\\n\", submissions_authors, \"\\n\")\n",
    "\n",
    "submissions_authors_unique = submissions_authors.drop_duplicates()\n",
    "print(\"Subreddits authors without duplicates:\\n\", submissions_authors_unique, \"\\n\")\n",
    "\n",
    "submissions_num_authors = submissions_authors_unique.groupby([\"subreddit\",\"subreddit_id\"]).author.count().reset_index()\n",
    "print(\"Subreddit num_authors:\\n\", submissions_num_authors, \"\\n\")\n",
    "\n",
    "max_num_authors = submissions_num_authors['author'].idxmax()\n",
    "max_num_authors_row = submissions_num_authors.iloc[max_num_authors]\n",
    "print(\"Subreddits with MAX num of authors:\\n\", max_num_authors_row, \"\\n\")\n",
    "\n",
    "max_num_authors_10_rows = submissions_num_authors.nlargest(5, 'author')\n",
    "print(\"First 10 subreddits with MAX num of authors:\\n\", max_num_authors_10_rows, \"\\n\")\n",
    "\n",
    "# sta raditi sa celijama gde je author==[deleted] ??\n",
    "\n",
    "# Q: Koji  su najvažniji po broju korisnika, a koji po broju komentara?\n",
    "# A: Po broju korisnika: reddit.com (138153), politics(15250), business(13009), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12779a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Kakav je prosečan broj zabeleženih korisnika aktivnih u posmatranom periodu po sabreditu? \n",
    "# Korisnik se smatra aktivnim na sabreditu ako je zabeležen barem jedan komentar ili objava tog korisnika.\n",
    "\n",
    "print(\"AUTHORS PER SUBMISSION:\\n\")\n",
    "submissions_authors = submissions_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Submissions authors:\\n\", submissions_authors, \"\\n\")\n",
    "\n",
    "submissions_authors_unique = submissions_authors.drop_duplicates()\n",
    "print(\"Submissions authors without duplicates:\\n\", submissions_authors_unique, \"\\n\")\n",
    "\n",
    "print(\"AUTHORS PER COMMENT:\\n\")\n",
    "comments_authors = comments_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Comments authors:\\n\", comments_authors, \"\\n\")\n",
    "\n",
    "comments_authors_unique = comments_authors.drop_duplicates()\n",
    "print(\"Comments authors without duplicates:\\n\", comments_authors_unique, \"\\n\")\n",
    "\n",
    "print(\"AUTHORS PER COMMENT AND PER SUBMISSION:\")\n",
    "subreddit_authors = pd.concat([comments_authors_unique, submissions_authors_unique])\n",
    "print(subreddit_authors.shape, \"\\n\")\n",
    "\n",
    "subreddit_authors_unique = subreddit_authors.drop_duplicates()\n",
    "print(\"Subreddit authors without duplicates:\\n\", subreddit_authors_unique, \"\\n\")\n",
    "\n",
    "subreddit_num_authors = subreddit_authors_unique.groupby([\"subreddit\",\"subreddit_id\"]).author.count().reset_index()\n",
    "print(\"Subreddit num_authors:\\n\", subreddit_num_authors, \"\\n\")\n",
    "\n",
    "subreddit_sum_authors = subreddit_num_authors['author'].sum()\n",
    "subreddit_authors_num_rows = subreddit_num_authors.shape[0]\n",
    "subreddit_authors_avg = round(subreddit_sum_authors/subreddit_authors_num_rows)\n",
    "print(\"Average number of authors per subreddit:\\n\", subreddit_authors_avg)\n",
    "\n",
    "# Q: Kakav je prosečan broj zabeleženih korisnika aktivnih u posmatranom periodu po sabreditu?\n",
    "# A: 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e11222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Ko su korisnici sa najvećim brojem objava, a ko korisnici sa najvećim brojem komentara? \n",
    "\n",
    "print(\"MAX SUBMISSIONS USERS:\\n\")\n",
    "max_submissions_users = submissions_data.author.value_counts()[:6]\n",
    "print(\"With deleted:\\n\", max_submissions_users)\n",
    "max_submissions_users_not_del = max_submissions_users.tail(max_submissions_users.shape[0] - 1)\n",
    "print(\"\\nUsers with max_submissions:\\n\", max_submissions_users_not_del)\n",
    "\n",
    "# Q: Ko su korisnici sa najvećim brojem objava, a ko korisnici sa najvećim brojem komentara? \n",
    "# A: Korisnici sa najvećim brojem objava: gst(18870), qgyh2(12238), ...\n",
    "\n",
    "print(\"\\nMAX COMMENTS USERS:\\n\")\n",
    "max_comments_users = comments_data.author.value_counts()[:6]\n",
    "print(\"With deleted:\\n\", max_comments_users)\n",
    "max_comments_users_not_del = max_comments_users.tail(max_comments_users.shape[0] - 1)\n",
    "print(\"\\nUsers with max_comments:\\n\", max_comments_users_not_del)\n",
    "\n",
    "# Q: Ko su korisnici sa najvećim brojem objava, a ko korisnici sa najvećim brojem komentara? \n",
    "# A: Korisnici sa najvećim brojem komentara: NoMoreNicksLeft(13480), malcontent(12159), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f380c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Koji korisnici su aktivni na najvećem broju sabredita? Na koliko su sabredita aktivni?\n",
    "\n",
    "print(\"SUBMISSION AUTHORS PER SUBREDDIT:\\n\")\n",
    "submissions_authors_4 = submissions_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Submissions authors:\\n\", submissions_authors_4.shape, \"\\n\")\n",
    "\n",
    "submissions_authors_unique_4 = submissions_authors_4.drop_duplicates()\n",
    "print(\"Submissions authors without duplicates:\\n\", submissions_authors_unique_4, \"\\n\")\n",
    "\n",
    "print(\"COMMENT AUTHORS PER SUBREDDIT:\\n\")\n",
    "comments_authors_4 = comments_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Comments authors:\\n\", comments_authors_4.shape, \"\\n\")\n",
    "\n",
    "comments_authors_unique_4 = comments_authors_4.drop_duplicates()\n",
    "print(\"Comments authors without duplicates:\\n\", comments_authors_unique_4, \"\\n\")\n",
    "\n",
    "print(\"COMMENT AND SUBMISSION AUTHORS PER SUBREDDIT:\")\n",
    "subreddit_authors_4 = pd.concat([comments_authors_unique_4, submissions_authors_unique_4])\n",
    "print(subreddit_authors_4.shape, \"\\n\")\n",
    "\n",
    "print(\"MAX SUBREDDIT USERS:\\n\")\n",
    "max_subreddit_users_4 = subreddit_authors_4.author.value_counts()[:6]\n",
    "print(\"With deleted:\\n\", max_subreddit_users_4, \"\\n\")\n",
    "max_subreddit_users_not_del_4 = max_subreddit_users_4.tail(max_subreddit_users_4.shape[0] - 1)\n",
    "print(\"Users active on max_subreddits:\\n\", max_subreddit_users_not_del_4)\n",
    "\n",
    "# Q: Koji korisnici su aktivni na najvećem broju sabredita? Na koliko su sabredita aktivni?\n",
    "# A: MrKlaatu(181), Escafane(154), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Kako su korelisani brojevi objava i brojevi komentara korisnika? Odrediti Pirsonov koeficijent korelacije i izvršiti vizuelizaciju.\n",
    "import scipy.stats as sc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"MAX SUBMISSIONS USERS:\\n\")\n",
    "max_submissions_users = submissions_data.author.value_counts().reset_index()\n",
    "max_submissions_users.columns = ['author', 'sub_count']\n",
    "max_submissions_users = max_submissions_users[max_submissions_users['author'] != '[deleted]']\n",
    "print(\"With deleted:\\n\", max_submissions_users)\n",
    "\n",
    "print(\"\\nMAX COMMENTS USERS:\\n\")\n",
    "max_comments_users = comments_data.author.value_counts().reset_index()\n",
    "max_comments_users.columns = ['author', 'com_count']\n",
    "max_comments_users = max_comments_users[max_comments_users['author'] != '[deleted]']\n",
    "print(\"With deleted:\\n\", max_comments_users)\n",
    "\n",
    "# from pathlib import Path  \n",
    "# filepath = Path('out.csv')\n",
    "# corell.to_csv(filepath)\n",
    "\n",
    "corell = pd.merge(max_submissions_users, max_comments_users, how=\"outer\", on=\"author\")\n",
    "corell = corell.fillna(0)\n",
    "\n",
    "corell_dtypes = {\n",
    "    \"sub_count\": int,\n",
    "    \"author\": object,\n",
    "    \"com_count\": int\n",
    "}\n",
    "corell = corell.astype(corell_dtypes)\n",
    "print(corell)\n",
    "\n",
    "x = corell['sub_count'].to_list()\n",
    "y = corell['com_count'].to_list()\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.xlabel(\"submissions\")\n",
    "plt.ylabel(\"comments\")\n",
    "plt.show()\n",
    "\n",
    "p_coeff = sc.pearsonr(x, y)\n",
    "print('Pearson correlation coefficient:', p_coeff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Koje objave poseduju najveći broj komentara i na kojim su sabreditima postavljene? \n",
    "# Prikazati podatke o tim objavama, uključujući to na kojem su sabreditu postavljene \n",
    "# i šta im je sadržaj (ako je polje objave “over 18” postavljeno na false).\n",
    "\n",
    "submissions_sorted_num_comments = submissions_data.sort_values(by='num_comments', ascending=False)\n",
    "# submissions_sorted_num_comments = submissions_sorted_num_comments[submissions_sorted_num_comments['over_18'] == False]\n",
    "\n",
    "submissions_sorted_num_comments_first10 = submissions_sorted_num_comments[:10] \n",
    "print(\"First 10 submissions sorted by number of comments:\\n\", submissions_sorted_num_comments_first10, \"\\n\")\n",
    "\n",
    "# Q: Koje objave poseduju najveći broj komentara i na kojim su sabreditima postavljene? \n",
    "# A: submission_id(subreddit, num_comments) = 6nz1k(science, 33329), 78n1v(WTF, 3657), ...\n",
    "\n",
    "urls = submissions_sorted_num_comments_first10['url'].to_list()\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791cf98",
   "metadata": {},
   "source": [
    "### Modelovanje mreže"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f274dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(set(unique_subreddits['subreddit_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93148e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_subreddit_id_author = submissions_data[['subreddit_id', 'author']]\n",
    "com_subreddit_id_author = comments_data[['subreddit_id', 'author']]\n",
    "\n",
    "print(\"Listing subreddits and authors:\\n\")\n",
    "print(sub_subreddit_id_author, '\\n')\n",
    "print(com_subreddit_id_author, '\\n')\n",
    "\n",
    "sub_subreddit_id_author = sub_subreddit_id_author[sub_subreddit_id_author['author'] != '[deleted]']\n",
    "com_subreddit_id_author = com_subreddit_id_author[com_subreddit_id_author['author'] != '[deleted]']\n",
    "\n",
    "print(\"After removed '[deleted]':\\n\")\n",
    "print(sub_subreddit_id_author, '\\n')\n",
    "print(com_subreddit_id_author, '\\n')\n",
    "\n",
    "sub_subreddit_id_author = sub_subreddit_id_author.drop_duplicates()\n",
    "com_subreddit_id_author = com_subreddit_id_author.drop_duplicates()\n",
    "\n",
    "print(\"After dropped duplicates:\\n\")\n",
    "print(sub_subreddit_id_author, '\\n')\n",
    "print(com_subreddit_id_author, '\\n')\n",
    "\n",
    "subreddit_id_author = pd.concat([sub_subreddit_id_author, com_subreddit_id_author])\n",
    "subreddit_id_author = subreddit_id_author.drop_duplicates()\n",
    "subreddit_id_author.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(\"After concationation and dropped duplicates:\\n\")\n",
    "print(subreddit_id_author, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f39e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_author = subreddit_id_author.groupby('author')\n",
    "\n",
    "for _, g in grouped_by_author:\n",
    "    sub_list = list(g.loc[:, 'subreddit_id'])\n",
    "    \n",
    "    if len(sub_list) > 1:\n",
    "        for i in range(len(sub_list) - 1):\n",
    "            for j in range(i + 1, len(sub_list)):\n",
    "                if (sub_list[i], sub_list[j]) in G.edges:\n",
    "                    G.edges[sub_list[i], sub_list[j]]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(sub_list[i], sub_list[j], weight=1)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"models/our_model.gml\"\n",
    "\n",
    "nx.write_gml(G, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19661449",
   "metadata": {},
   "source": [
    "# Osnovna karakterizacija modelovanih mreža (3.4.2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"models/our_model.gml\"\n",
    "G = nx.read_gml(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124de9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Graph: \", nx.info(G))\n",
    "print(\"Graph isolates: \", nx.number_of_isolates(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd21335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_component(gra):\n",
    "    largest_cc = max(nx.connected_components(gra), key=len)\n",
    "    gra_dom = gra.subgraph(largest_cc).copy()\n",
    "    print(f\"Dominantna komponenta ima {len(gra_dom.nodes())} čvorova i {len(gra_dom.edges())} grana\")\n",
    "    return gra_dom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046f97a",
   "metadata": {},
   "source": [
    "#### Network Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 7) Kolika je gustina mreže?\n",
    "\n",
    "# (Gephi) Graph Density: 0.012\n",
    "print(\"Graph Density: \", nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba25ca",
   "metadata": {},
   "source": [
    "#### Network Shortest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 8) Kolike su prosečne distance u okviru mreže i dijametar mreže?\n",
    "\n",
    "# (Gephi) Average Path length: 2.098559911126496\n",
    "# (Gephi) Network Diameter: 5 \n",
    "\n",
    "Gdom = get_largest_component(G)\n",
    "print(nx.diameter(Gdom)) # NetworkXError: Found infinite path length because the graph is not connected\n",
    "print(nx.average_shortest_path_length(Gdom)) # NetworkXError: Graph is not connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c05d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 9) U kojoj meri je mreža povezana i centralizovana? \n",
    "# Navesti broj i veličine povezanih komponenata i proceniti da li postoji gigantska komponenta. \n",
    "\n",
    "# Broj povezanih komponenata\n",
    "\n",
    "# (Gephi) Number of Weakly Connected Components: 1486\n",
    "print(\"Graph - is_connected: \", nx.is_connected(G))\n",
    "print(\"Number of connected components: \", nx.number_connected_components(G))\n",
    "\n",
    "# Veličine povezanih komponenata\n",
    "\n",
    "print(\"Largest connected component: \", len(max(nx.connected_components(G), key=len)))\n",
    "print(\"Sorted list of connected components, largest first:\")\n",
    "com_list = [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "print(com_list)\n",
    "# Postoji gigantska komponenta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b841f1",
   "metadata": {},
   "source": [
    "#### Network Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10) Koliki je prosečni, a koliki globalni koeficijent klasterizacije mreže? \n",
    "# Kakva je raspodela lokalnog koeficijenta klasterizacije njenih čvorova? \n",
    "# Da li je klasterisanje izraženo ili ne? Odgovor dati upoređivanjem sa slučajno generisanom Erdos-Renyi mrežom istih dimenzija. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global clustering coefficient\n",
    "\n",
    "# The global clustering coefficient is based on triplets of nodes.\n",
    "# A triplet is three nodes that are connected by either two (open triplet) or three (closed triplet) undirected ties.\n",
    "# The global clustering coefficient is the number of closed triplets (or 3 x triangles) over the total number of triplets (both open and closed). \n",
    "# global_cc = (number of closed triplets) / (number of all triplets)\n",
    "\n",
    "# Compute graph transitivity, the fraction of all possible triangles present in G.\n",
    "# Possible triangles are identified by the number of \"triads\" (two edges with a shared vertex).\n",
    "# The transitivity is:  T = 3*(triangles/triads)\n",
    "\n",
    "tr = nx.transitivity(G)\n",
    "print(f\"Global clustering coefficient: {tr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average clustering coefficient\n",
    "\n",
    "# (Gephi) Average Clustering Coefficient: 0.907\n",
    "# (Gephi) Dominant Component Average Clustering Coefficient: 0.907\n",
    "print(\"Average clustering coefficient: \", nx.average_clustering(G))\n",
    "print(\"Average clustering coefficient dominant: \", nx.average_clustering(Gdom))\n",
    "\n",
    "print(\"Average clustering coefficient: \", nx.average_clustering(G, count_zeros = False))\n",
    "print(\"Average clustering coefficient dominant: \", nx.average_clustering(Gdom, count_zeros = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f43db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Local clustering coefficient\n",
    "\n",
    "subreddit_id, clustering_coef = zip(*nx.clustering(G, weight = \"weight\").items())\n",
    "\n",
    "notZero = [(sub_id, cc)  for sub_id, cc in zip(subreddit_id, clustering_coef) if cc > 0]\n",
    "\n",
    "df = pd.DataFrame(notZero, columns = [\"id\", \"cc\"])\n",
    "df.sort_values('cc', inplace = True)\n",
    "\n",
    "print(\"Max local clustering coefficient: \", max(clustering_coef))\n",
    "print(\"Local clustering coefficients != 0 :\") \n",
    "print(df)\n",
    "\n",
    "# raspodela lokalnog koeficijenta klasterizacije ???\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('cc', inplace=True, ascending=False)\n",
    "y = df['cc'].to_list()\n",
    "plt.xlabel(\"Број чворова\")\n",
    "plt.ylabel(\"Коефицијент кластеризације\")\n",
    "plt.plot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbfea6a",
   "metadata": {},
   "source": [
    "###### Erdos-Renyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "p = ( 2*float(m) ) / ( n* (n-1) )\n",
    "\n",
    "er_network = nx.erdos_renyi_graph(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a18131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da li je klasterisanje izraženo ili ne?\n",
    "\n",
    "print(\"Erdos-Renyi Average cc\", nx.average_clustering(er_network, count_zeros = False))\n",
    "print(\"Erdos-Renyi Global cc\", nx.transitivity(er_network))\n",
    "\n",
    "# A: Izrazenije nego u er mrezi: Da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea280d",
   "metadata": {},
   "source": [
    "#### Small World Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b32e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 11) Na osnovu odgovora na pitanja 8 i 10, proceniti da li mreža iskazuje osobine malog sveta.\n",
    "\n",
    "# A small-world network is a type of mathematical graph in which most nodes are not neighbors of one another, but \n",
    "# the neighbors of any given node are likely to be neighbors of each other and most nodes can be reached \n",
    "# from every other node by a small number of hops or steps.\n",
    "\n",
    "# A small world network is characterized by a small average shortest path length, and a large clustering coefficient\n",
    "# Small-worldness is commonly measured with the coefficient sigma or omega.\n",
    "# Both coefficients compare the average clustering coefficient and shortest path length of a given graph \n",
    "# against the same quantities for an equivalent random or lattice graph. (watts_strogatz_graph)\n",
    "\n",
    "# if sigma > 1 network is small-world. \n",
    "#nx.sigma(G) # forever\n",
    "\n",
    "# Erdos-Renyi network:\n",
    "# nx.average_shortest_path_length(er_network) # result: 2.444373264140706\n",
    "# Erdos-Renyi Average cc 0.012376659911008338\n",
    "\n",
    "# ANSWER:\n",
    "# (Gephi) Average Path length: 2.098559911126496\n",
    "# Average clustering coefficient:  0.907\n",
    "\n",
    "# Da. (Visok koef. klasterizacije i mala prosecna distanca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781e50d",
   "metadata": {},
   "source": [
    "#### Network Assortativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9675bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 12) Izvršiti asortativnu analizu po stepenu čvora i dati odgovor da li je izraženo asortativno mešanje. \n",
    "# U slučaju da je mreža usmerena, analizu izvršiti i po ulaznom i po izlaznom stepenu čvora. \n",
    "# Priložiti i vizuelizaciju. \n",
    "\n",
    "## asortativnost na osnovu netežinskog stepena čvora\n",
    "print(\"Degree assortativity coefficient: \", nx.degree_assortativity_coefficient(G))\n",
    "## asortativnost na osnovu težinskog stepena čvora\n",
    "print(\"Degree assortativity coefficient (weight): \", nx.degree_assortativity_coefficient(G, weight='weight'))\n",
    "\n",
    "# Assortativity measures the similarity of connections in the graph with respect to the node degree.\n",
    "## Asortativna mreža => čvorovi sličnog stepena se vezuju međusobno\n",
    "\n",
    "# Positive values of r indicate a correlation between nodes of similar degree, \n",
    "# while negative values indicate relationships between nodes of different degree. \n",
    "# In general, r lies between −1 and 1. \n",
    "# When r = 1, the network is said to have perfect assortative mixing patterns,\n",
    "# when r = 0 the network is non-assortative,\n",
    "# while at r = −1 the network is completely disassortative.\n",
    "\n",
    "# ANSWER:\n",
    "# Mreža je disasortativna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40645906",
   "metadata": {},
   "source": [
    "#### Rich Club Phenomenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 13) Da li mreža ispoljava fenomen kluba bogatih (eng. rich club phenomenon)? \n",
    "\n",
    "# Rich-club can be viewed as a more specific notation of assortativity, where we are only concerned with the connectivity of nodes beyond a certain richness metric.\n",
    "# The rich-club coefficient is a metric on graphs and networks, designed to measure the extent to which well-connected nodes also connect to each other. \n",
    "\n",
    "#nx.rich_club_coefficient(G) # forever\n",
    "rcc = nx.rich_club_coefficient(G, normalized=False)\n",
    "print(rcc)\n",
    "\n",
    "plt.plot(rcc.values())\n",
    "plt.show()\n",
    "\n",
    "rcc = None\n",
    "# ANSWER: Ne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a07a0",
   "metadata": {},
   "source": [
    "#### Distribution Degree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497255d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 14) Kakva je distribucija čvorova po stepenu i da li prati power law raspodelu?\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "def plot_deg_frequency(G, weighted = False, xscale = \"log\", yscale = \"log\"):\n",
    "\n",
    "    if weighted:\n",
    "        degrees = G.degree(weight=\"weight\")\n",
    "    else:\n",
    "        degrees = G.degree()\n",
    "        \n",
    "    _, deg_list = zip(*degrees)\n",
    "    deg_counts = Counter(deg_list)        \n",
    "    #print(deg_counts)\n",
    "    x, y = zip(*deg_counts.items())                                                      \n",
    "\n",
    "    plt.figure(1)   \n",
    "\n",
    "    # prep axes   \n",
    "    if weighted:\n",
    "        plt.xlabel('weighted degree')  \n",
    "    else:\n",
    "        plt.xlabel('degree')                                                                                                             \n",
    "    plt.xscale(xscale)                                                                                                                \n",
    "    plt.xlim(1, max(x))  \n",
    "\n",
    "    plt.ylabel('frequency')                                                                                                          \n",
    "    plt.yscale(yscale)                                                                                                                \n",
    "    plt.ylim(1, max(y))                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "    plt.scatter(x, y, marker='.')                                                                                                    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_deg_frequency(G) # Raspodele stepena čvora\n",
    "plot_deg_frequency(G, weighted = True) # Raspodela težinskog stepena čvora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erdos-Renyi Graph:\")\n",
    "plot_deg_frequency(er_network, xscale = 'linear', yscale = 'linear')\n",
    "plot_deg_frequency(er_network, xscale = 'log', yscale = 'log')\n",
    "\n",
    "print(\"Our Graph G:\")\n",
    "plot_deg_frequency(G, xscale = 'linear', yscale = 'linear')\n",
    "plot_deg_frequency(G, xscale = 'log', yscale = 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93cd2c8",
   "metadata": {},
   "source": [
    "#### Fitting to the Power-Law Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_weights = 0\n",
    "\n",
    "for n in Gdom.edges.data():\n",
    "    sum_of_weights += n[2]['weight']\n",
    "    \n",
    "print(sum_of_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = sorted([d for n, d in Gdom.degree()], reverse=True)\n",
    "degreeCount = Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "\n",
    "max_deg = max(deg) # hoćemo po jedan bin za svaki stepen čvora\n",
    "\n",
    "# izračunavanje histograma\n",
    "values, base = np.histogram(deg, bins = max_deg)\n",
    "\n",
    "# kumulativna suma (inkluzivna prefiksna suma)\n",
    "cumulative = np.cumsum(values)\n",
    "\n",
    "# plotovanje komplementarne kumulativne raspodele stepena čvora P(X>x)\n",
    "plt.plot(base[:-1], [float(x)/sum_of_weights for x in sum_of_weights - cumulative], c='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ce0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9870c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = powerlaw.Fit(degree_sequence)\n",
    "\n",
    "print(results.supported_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.power_law.alpha)\n",
    "print(results.power_law.xmin)\n",
    "print(results.power_law.sigma)\n",
    "R, p = results.distribution_compare('power_law', 'exponential')\n",
    "print(f\"Loglikelihood ratio: {R}\")\n",
    "print(f\"Statistical significance: {p}\")\n",
    "R, p = results.distribution_compare('power_law', 'truncated_power_law')\n",
    "print(f\"Loglikelihood ratio: {R}\")\n",
    "print(f\"Statistical significance: {p}\")\n",
    "R, p = results.distribution_compare('exponential', 'truncated_power_law')\n",
    "print(f\"Loglikelihood ratio: {R}\")\n",
    "print(f\"Statistical significance: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d633f",
   "metadata": {},
   "source": [
    "#### Hubs and authorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2421d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 15) Odrediti najvažnije habove i autoritete u mreži. \n",
    "# Kako su oni raspoređeni i ugrađeni u mrežu, da li su na periferiji ili u jezgru mreže?\n",
    "\n",
    "# Hubs and authorities are a natural generalization of eigenvector centrality.\n",
    "# A high hub actor points to many good authories and \n",
    "# a high authority actor receives from many good hubs. \n",
    "\n",
    "# Mreza je neusmerena -> nema habove i autoritete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiG = nx.DiGraph()\n",
    "\n",
    "DiG.add_nodes_from([1, 2])\n",
    "DiG.add_edge(1, 2)\n",
    "DiG.add_edge(1, 2)\n",
    "DiG.add_edge(2, 1)\n",
    "DiG.edges[1, 2]['weight'] = 2;\n",
    "DiG.edges[2, 1]['weight'] = 1;\n",
    "\n",
    "nx.write_gml(DiG, \"models/test.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35f8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
