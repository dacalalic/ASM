{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97172091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff422d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_path = 'ASM_PZ2_podaci_2122/reddit2008/comments_2008_asm/csv-{}.csv'\n",
    "comments_list = []\n",
    "for i in range(0, 12):\n",
    "    comments_list.append(pd.read_csv(comments_path.format(i)))\n",
    "\n",
    "comments_dtypes = {\n",
    "    \"id\": object,\n",
    "    \"author\": object,\n",
    "    \"link_id\": object,\n",
    "    \"parent_id\": object,\n",
    "    \"created_utc\": int,\n",
    "    \"subreddit\": object,\n",
    "    \"subreddit_id\": object,\n",
    "    \"score\": int,\n",
    "    \"distinguished\": object,\n",
    "    \"gilded\": int,\n",
    "    \"controversiality\": int\n",
    "}\n",
    "#comments_data = comments_data.astype(comments_dtypes)\n",
    "    \n",
    "comments_data = pd.concat(comments_list)\n",
    "comments_list = []\n",
    "comments_data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(comments_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6576e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_path = 'ASM_PZ2_podaci_2122/reddit2008/submissions_2008_asm/csv-{}.csv'\n",
    "submissions_list = []\n",
    "for i in range(0, 12):\n",
    "    submissions_list.append(pd.read_csv(submissions_path.format(i)))\n",
    "\n",
    "submissions_dtypes = {\n",
    "    \"id\": object,\n",
    "    \"url\": object,\n",
    "    \"permalink\": object,\n",
    "    \"author\": object,\n",
    "    \"created_utc\": int,\n",
    "    \"subreddit\": object,\n",
    "    \"subreddit_id\": object,\n",
    "    \"num_comments\": int,\n",
    "    \"score\": int,\n",
    "    \"over_18\": bool,\n",
    "    \"distinguished\": object,\n",
    "    \"domain\": object,\n",
    "    \"stickied\": bool,\n",
    "    \"locked\": bool,\n",
    "    \"hide_score\": bool\n",
    "}\n",
    "#submissions_data = submissions_data.astype(submissions_dtypes)\n",
    "    \n",
    "submissions_data = pd.concat(submissions_list)\n",
    "submissions_list = []\n",
    "submissions_data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(submissions_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2e0ae",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comments_data['id'].isnull().values.any())\n",
    "print(comments_data['id'].is_unique)\n",
    "\n",
    "print(submissions_data['id'].isnull().values.any())\n",
    "print(submissions_data['id'].is_unique)\n",
    "\n",
    "comments_null_id = comments_data[comments_data['id'].isnull()]\n",
    "print(\"\\n\", comments_null_id)\n",
    "\n",
    "print(\"\\n\", comments_data.iloc[6422486:6422489, :])\n",
    "\n",
    "comments_data.loc[comments_data['id'].isnull(), 'id'] = \"nan\"\n",
    "\n",
    "print(\"\\nAfter id null fix:\\n\", comments_data.iloc[6422486:6422489, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec1c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unnamed column COMMENTS\n",
    "print(comments_data.columns)\n",
    "print(comments_data[\"Unnamed: 0\"])\n",
    "\n",
    "comments_data = comments_data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(\"\\n\", comments_data.columns)\n",
    "\n",
    "# Unnamed column SUBMISSIONS\n",
    "print(\"\\n\", submissions_data.columns)\n",
    "print(submissions_data[\"Unnamed: 0\"])\n",
    "\n",
    "submissions_data = submissions_data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(\"\\n\", submissions_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecf810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments_contr_not_zero = comments_data[comments_data['controversiality'] != 0]\n",
    "print(\"\\n\", comments_contr_not_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null columns - COMMENTS\n",
    "nan_values = comments_data.isna()\n",
    "nan_columns = nan_values.any()\n",
    "columns_with_nan = comments_data.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f37bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments_dis_not_null = comments_data[comments_data['distinguished'].isnull() == False]\n",
    "print(\"\\n\", comments_dis_not_null.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c399cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null columns - SUBMISSIONS\n",
    "nan_values = submissions_data.isna()\n",
    "nan_columns = nan_values.any()\n",
    "columns_with_nan = submissions_data.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_dis_not_null = submissions_data[submissions_data['distinguished'].isnull() == False]\n",
    "print(\"\\n\", submissions_dis_not_null.shape)\n",
    "\n",
    "submissions_domain_not_null = submissions_data[submissions_data['domain'].isnull() == True]\n",
    "print(\"\\n\", submissions_domain_not_null.shape)\n",
    "#print(\"\\n\", submissions_domain_not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47445275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types check\n",
    "print(comments_data.dtypes, \"\\n\")\n",
    "print(submissions_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed900224",
   "metadata": {},
   "source": [
    "# Statistička obrada podataka (3.4.1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50538ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Koliko postoji različitih sabredita koji se pojavljuju u posmatranom periodu? Koji su najvažniji po broju korisnika, a koji po broju komentara? \n",
    "\n",
    "submissions_subreddit_columns = submissions_data.loc[:,'subreddit' : 'subreddit_id']\n",
    "submissions_subreddit_columns = submissions_subreddit_columns.drop_duplicates()\n",
    "print(\"SUBMISSIONS Subreddits:\\n\", submissions_subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "comments_subreddit_columns = comments_data.loc[:, 'subreddit' : 'subreddit_id']\n",
    "comments_subreddit_columns = comments_subreddit_columns.drop_duplicates()\n",
    "print(\"COMMENTS Subreddits:\\n\", comments_subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "subreddit_columns = pd.concat([submissions_subreddit_columns, comments_subreddit_columns])\n",
    "print(\"ALL Subreddits:\\n\", subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "subreddit_columns = subreddit_columns.drop_duplicates()\n",
    "print(\"UNIQUE Subreddit pairs:\\n\", subreddit_columns.shape, \"\\n\")\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "# check for nonuniqueness (subreddits, subreddit IDs)\n",
    "print(\"\\nCHECK FOR NONUNIQUENESS\\n\")\n",
    "print(\"submissions_data subreddit_id - is unique: \", submissions_subreddit_columns['subreddit_id'].is_unique)\n",
    "print(\"comments_data subreddit_id - is unique: \", comments_subreddit_columns['subreddit_id'].is_unique)\n",
    "print(\"Column subreddit - is unique: \", subreddit_columns['subreddit'].is_unique)\n",
    "print(\"Column subreddit_id - is unique: \", subreddit_columns['subreddit_id'].is_unique, \"\\n\")\n",
    "\n",
    "data_grouped = subreddit_columns[['subreddit', 'subreddit_id']].groupby('subreddit_id')\n",
    "\n",
    "data_aggregated = data_grouped['subreddit_id'].agg(np.size)\n",
    "#print(data_aggregated, \"\\n\")\n",
    "\n",
    "data_nonunique = data_aggregated[data_aggregated > 1]\n",
    "print(data_nonunique, \"\\n\")\n",
    "\n",
    "target_match_list = data_nonunique.keys()[:]\n",
    "#print(\"Nonunique IDs:\", target_match_list, \"\\n\")\n",
    "\n",
    "data_target = subreddit_columns[subreddit_columns['subreddit_id'].isin(target_match_list)]\n",
    "print(data_target, \"\\n\")\n",
    "\n",
    "print(\"COMMENTS data rows with target_match IDs:\\n\")\n",
    "comments_target_rows = comments_data[comments_data['subreddit_id'].isin(target_match_list)]\n",
    "comments_target_rows = comments_target_rows.drop_duplicates('subreddit_id')\n",
    "print(comments_target_rows, \"\\n\")\n",
    "\n",
    "print(\"SUBMISSIONS data rows with target_match IDs:\\n\")\n",
    "submissions_target_rows = submissions_data[submissions_data['subreddit_id'].isin(target_match_list)]\n",
    "submissions_target_rows = submissions_target_rows.drop_duplicates('subreddit_id')\n",
    "print(submissions_target_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b08c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Before:\\n\", subreddit_columns, \"\\n\")\n",
    "unique_subreddits_1 = subreddit_columns[~((subreddit_columns['subreddit'] == '_Descary') & (subreddit_columns['subreddit_id'] == 't5_2qj0s'))]\n",
    "unique_subreddits = unique_subreddits_1[~((unique_subreddits_1['subreddit'] == '__Journalism') & (unique_subreddits_1['subreddit_id'] == 't5_2qhyl'))]\n",
    "print(\"After:\\n\", unique_subreddits)\n",
    "\n",
    "# Q: Koliko postoji različitih sabredita koji se pojavljuju u posmatranom periodu? \n",
    "# ANSWER: 5032\n",
    "\n",
    "# Changing subreddit (with same IDs) names from _Name to Name ##### TREBALO BI PROMENITI I permalink\n",
    "submissions_data.loc[submissions_data['subreddit_id'] == 't5_2qj0s', 'subreddit'] = 'Descary'\n",
    "submissions_data.loc[submissions_data['subreddit_id'] == 't5_2qhyl', 'subreddit'] = 'Journalism'\n",
    "\n",
    "submissions_rows = submissions_data[submissions_data['subreddit_id'].isin(target_match_list)]\n",
    "submissions_rows = submissions_rows.drop_duplicates('subreddit_id')\n",
    "print(submissions_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f1c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"SUBREDDIT WITH MAX NUMBER OF COMMENTS:\\n\")\n",
    "submissions_num_comments = submissions_data.groupby([\"subreddit\",\"subreddit_id\"]).num_comments.sum().reset_index()\n",
    "print(\"Subreddits num_comments:\\n\", submissions_num_comments, \"\\n\")\n",
    "\n",
    "max_num_comments = submissions_num_comments['num_comments'].idxmax()\n",
    "max_num_comments_row = submissions_num_comments.iloc[max_num_comments]\n",
    "print(\"Subreddits with MAX num of comments:\\n\", max_num_comments_row, \"\\n\")\n",
    "\n",
    "max_num_comments_10_rows = submissions_num_comments.nlargest(10, 'num_comments')\n",
    "print(\"First 10 subreddits with MAX num of comments:\\n\", max_num_comments_10_rows, \"\\n\")\n",
    "\n",
    "# Q: Koji su najvažniji po broju korisnika, a koji po broju komentara?\n",
    "# A: Po broju komentara: reddit.com (1768764), politics(1059618), programming(421137), ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUBREDDIT WITH MAX NUMBER OF USERS:\\n\")\n",
    "submissions_authors = submissions_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Subreddits authors:\\n\", submissions_authors, \"\\n\")\n",
    "\n",
    "submissions_authors_unique = submissions_authors.drop_duplicates()\n",
    "print(\"Subreddits authors without duplicates:\\n\", submissions_authors_unique, \"\\n\")\n",
    "\n",
    "submissions_num_authors = submissions_authors_unique.groupby([\"subreddit\",\"subreddit_id\"]).author.count().reset_index()\n",
    "print(\"Subreddit num_authors:\\n\", submissions_num_authors, \"\\n\")\n",
    "\n",
    "max_num_authors = submissions_num_authors['author'].idxmax()\n",
    "max_num_authors_row = submissions_num_authors.iloc[max_num_authors]\n",
    "print(\"Subreddits with MAX num of authors:\\n\", max_num_authors_row, \"\\n\")\n",
    "\n",
    "max_num_authors_10_rows = submissions_num_authors.nlargest(5, 'author')\n",
    "print(\"First 10 subreddits with MAX num of authors:\\n\", max_num_authors_10_rows, \"\\n\")\n",
    "\n",
    "# sta raditi sa celijama gde je author==[deleted] ??\n",
    "\n",
    "# Q: Koji  su najvažniji po broju korisnika, a koji po broju komentara?\n",
    "# A: Po broju korisnika: reddit.com (138153), politics(15250), business(13009), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Kakav je prosečan broj zabeleženih korisnika aktivnih u posmatranom periodu po sabreditu? \n",
    "# Korisnik se smatra aktivnim na sabreditu ako je zabeležen barem jedan komentar ili objava tog korisnika.\n",
    "\n",
    "print(\"AUTHORS PER SUBMISSION:\\n\")\n",
    "submissions_authors = submissions_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Submissions authors:\\n\", submissions_authors, \"\\n\")\n",
    "\n",
    "submissions_authors_unique = submissions_authors.drop_duplicates()\n",
    "print(\"Submissions authors without duplicates:\\n\", submissions_authors_unique, \"\\n\")\n",
    "\n",
    "print(\"AUTHORS PER COMMENT:\\n\")\n",
    "comments_authors = comments_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Comments authors:\\n\", comments_authors, \"\\n\")\n",
    "\n",
    "comments_authors_unique = comments_authors.drop_duplicates()\n",
    "print(\"Comments authors without duplicates:\\n\", comments_authors_unique, \"\\n\")\n",
    "\n",
    "print(\"AUTHORS PER COMMENT AND PER SUBMISSION:\")\n",
    "subreddit_authors = pd.concat([comments_authors_unique, submissions_authors_unique])\n",
    "print(subreddit_authors.shape, \"\\n\")\n",
    "\n",
    "subreddit_authors_unique = subreddit_authors.drop_duplicates()\n",
    "print(\"Subreddit authors without duplicates:\\n\", subreddit_authors_unique, \"\\n\")\n",
    "\n",
    "subreddit_num_authors = subreddit_authors_unique.groupby([\"subreddit\",\"subreddit_id\"]).author.count().reset_index()\n",
    "print(\"Subreddit num_authors:\\n\", subreddit_num_authors, \"\\n\")\n",
    "\n",
    "subreddit_sum_authors = subreddit_num_authors['author'].sum()\n",
    "subreddit_authors_num_rows = subreddit_num_authors.shape[0]\n",
    "subreddit_authors_avg = round(subreddit_sum_authors/subreddit_authors_num_rows)\n",
    "print(\"Average number of authors per subreddit:\\n\", subreddit_authors_avg)\n",
    "\n",
    "# Q: Kakav je prosečan broj zabeleženih korisnika aktivnih u posmatranom periodu po sabreditu?\n",
    "# A: 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78771b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Ko su korisnici sa najvećim brojem objava, a ko korisnici sa najvećim brojem komentara? \n",
    "\n",
    "print(\"MAX SUBMISSIONS USERS:\\n\")\n",
    "max_submissions_users = submissions_data.author.value_counts()[:6]\n",
    "print(\"With deleted:\\n\", max_submissions_users)\n",
    "max_submissions_users_not_del = max_submissions_users.tail(max_submissions_users.shape[0] - 1)\n",
    "print(\"\\nUsers with max_submissions:\\n\", max_submissions_users_not_del)\n",
    "\n",
    "# Q: Ko su korisnici sa najvećim brojem objava, a ko korisnici sa najvećim brojem komentara? \n",
    "# A: Korisnici sa najvećim brojem objava: gst(18870), qgyh2(12238), ...\n",
    "\n",
    "print(\"\\nMAX COMMENTS USERS:\\n\")\n",
    "max_comments_users = comments_data.author.value_counts()[:6]\n",
    "print(\"With deleted:\\n\", max_comments_users)\n",
    "max_comments_users_not_del = max_comments_users.tail(max_comments_users.shape[0] - 1)\n",
    "print(\"\\nUsers with max_comments:\\n\", max_comments_users_not_del)\n",
    "\n",
    "# Q: Ko su korisnici sa najvećim brojem objava, a ko korisnici sa najvećim brojem komentara? \n",
    "# A: Korisnici sa najvećim brojem komentara: NoMoreNicksLeft(13480), malcontent(12159), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Koji korisnici su aktivni na najvećem broju sabredita? Na koliko su sabredita aktivni?\n",
    "\n",
    "print(\"SUBMISSION AUTHORS PER SUBREDDIT:\\n\")\n",
    "submissions_authors_4 = submissions_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Submissions authors:\\n\", submissions_authors_4.shape, \"\\n\")\n",
    "\n",
    "submissions_authors_unique_4 = submissions_authors_4.drop_duplicates()\n",
    "print(\"Submissions authors without duplicates:\\n\", submissions_authors_unique_4, \"\\n\")\n",
    "\n",
    "print(\"COMMENT AUTHORS PER SUBREDDIT:\\n\")\n",
    "comments_authors_4 = comments_data[['subreddit', 'subreddit_id', 'author']]\n",
    "print(\"Comments authors:\\n\", comments_authors_4.shape, \"\\n\")\n",
    "\n",
    "comments_authors_unique_4 = comments_authors_4.drop_duplicates()\n",
    "print(\"Comments authors without duplicates:\\n\", comments_authors_unique_4, \"\\n\")\n",
    "\n",
    "print(\"COMMENT AND SUBMISSION AUTHORS PER SUBREDDIT:\")\n",
    "subreddit_authors_4 = pd.concat([comments_authors_unique_4, submissions_authors_unique_4])\n",
    "print(subreddit_authors_4.shape, \"\\n\")\n",
    "\n",
    "print(\"MAX SUBREDDIT USERS:\\n\")\n",
    "max_subreddit_users_4 = subreddit_authors_4.author.value_counts()[:6]\n",
    "print(\"With deleted:\\n\", max_subreddit_users_4, \"\\n\")\n",
    "max_subreddit_users_not_del_4 = max_subreddit_users_4.tail(max_subreddit_users_4.shape[0] - 1)\n",
    "print(\"Users active on max_subreddits:\\n\", max_subreddit_users_not_del_4)\n",
    "\n",
    "# Q: Koji korisnici su aktivni na najvećem broju sabredita? Na koliko su sabredita aktivni?\n",
    "# A: MrKlaatu(181), Escafane(154), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ddd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Kako su korelisani brojevi objava i brojevi komentara korisnika? Odrediti Pirsonov koeficijent korelacije i izvršiti vizuelizaciju.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Koje objave poseduju najveći broj komentara i na kojim su sabreditima postavljene? \n",
    "# Prikazati podatke o tim objavama, uključujući to na kojem su sabreditu postavljene \n",
    "# i šta im je sadržaj (ako je polje objave “over 18” postavljeno na false).\n",
    "\n",
    "submissions_sorted_num_comments = submissions_data.sort_values(by='num_comments', ascending=False)\n",
    "submissions_sorted_num_comments = submissions_sorted_num_comments[submissions_sorted_num_comments['over_18'] == False]\n",
    "\n",
    "submissions_sorted_num_comments_first10 = submissions_sorted_num_comments[:10] \n",
    "print(\"First 10 submissions sorted by number of comments:\\n\", submissions_sorted_num_comments_first10, \"\\n\")\n",
    "\n",
    "# Q: Koje objave poseduju najveći broj komentara i na kojim su sabreditima postavljene? \n",
    "# A: submission_id(subreddit, num_comments) = 6nz1k(science, 33329), 78n1v(WTF, 3657), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b60dd",
   "metadata": {},
   "source": [
    "### Modelovanje mreže"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d96ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(set(unique_subreddits['subreddit_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8076f76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_subreddit_id_author = submissions_data[['subreddit_id', 'author']]\n",
    "com_subreddit_id_author = comments_data[['subreddit_id', 'author']]\n",
    "\n",
    "print(\"Listing subreddits and authors:\\n\")\n",
    "print(sub_subreddit_id_author, '\\n')\n",
    "print(com_subreddit_id_author, '\\n')\n",
    "\n",
    "sub_subreddit_id_author = sub_subreddit_id_author[sub_subreddit_id_author['author'] != '[deleted]']\n",
    "com_subreddit_id_author = com_subreddit_id_author[com_subreddit_id_author['author'] != '[deleted]']\n",
    "\n",
    "print(\"After removed '[deleted]':\\n\")\n",
    "print(sub_subreddit_id_author, '\\n')\n",
    "print(com_subreddit_id_author, '\\n')\n",
    "\n",
    "sub_subreddit_id_author = sub_subreddit_id_author.drop_duplicates()\n",
    "com_subreddit_id_author = com_subreddit_id_author.drop_duplicates()\n",
    "\n",
    "print(\"After dropped duplicates:\\n\")\n",
    "print(sub_subreddit_id_author, '\\n')\n",
    "print(com_subreddit_id_author, '\\n')\n",
    "\n",
    "subreddit_id_author = pd.concat([sub_subreddit_id_author, com_subreddit_id_author])\n",
    "subreddit_id_author = subreddit_id_author.drop_duplicates()\n",
    "subreddit_id_author.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(\"After concationation and dropped duplicates:\\n\")\n",
    "print(subreddit_id_author, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_author = subreddit_id_author.groupby('author')\n",
    "\n",
    "for _, g in grouped_by_author:\n",
    "    sub_list = list(g.loc[:, 'subreddit_id'])\n",
    "    \n",
    "    if len(sub_list) > 1:\n",
    "        for i in range(len(sub_list) - 1):\n",
    "            for j in range(i + 1, len(sub_list)):\n",
    "                if (sub_list[i], sub_list[j]) in G.edges:\n",
    "                    G.edges[sub_list[i], sub_list[j]]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(sub_list[i], sub_list[j], weight=1)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf88323",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"models/our_model.gml\"\n",
    "\n",
    "nx.write_gml(G, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64d3d5",
   "metadata": {},
   "source": [
    "# Osnovna karakterizacija modelovanih mreža (3.4.2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a7b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(nx.info(G))\n",
    "\n",
    "# Gephi\n",
    "\n",
    "### 7) Kolika je gustina mreže?\n",
    "\n",
    "# (Gephi) Graph Density: 0.012\n",
    "\n",
    "### 8) Kolike su prosečne distance u okviru mreže i dijametar mreže?\n",
    "\n",
    "# (Gephi) Average Path length: 2.098559911126496\n",
    "# (Gephi) Network Diameter: 5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 9) U kojoj meri je mreža povezana i centralizovana? \n",
    "# Navesti broj i veličine povezanih komponenata i proceniti da li postoji gigantska komponenta. \n",
    "\n",
    "# (Gephi) Number of Weakly Connected Components: 1486\n",
    "# (Gephi) Size -> 0                        - ?\n",
    "# (Gephi) Ne postoji gigantska komponenta. - ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bce5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raspodele stepena čvora\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "def plot_deg_frequency(G, weighted = False, xscale = \"log\", yscale = \"log\"):\n",
    "\n",
    "    if weighted:\n",
    "        degrees = G.degree(weight=\"weight\")\n",
    "    else:\n",
    "        degrees = G.degree()\n",
    "        \n",
    "    _, deg_list = zip(*degrees)\n",
    "    deg_counts = Counter(deg_list)        \n",
    "    print(deg_counts)\n",
    "    x, y = zip(*deg_counts.items())                                                      \n",
    "\n",
    "    plt.figure(1)   \n",
    "\n",
    "    # prep axes   \n",
    "    if weighted:\n",
    "        plt.xlabel('weighted degree')  \n",
    "    else:\n",
    "        plt.xlabel('degree')                                                                                                             \n",
    "    plt.xscale(xscale)                                                                                                                \n",
    "    plt.xlim(1, max(x))  \n",
    "\n",
    "    plt.ylabel('frequency')                                                                                                          \n",
    "    plt.yscale(yscale)                                                                                                                \n",
    "    plt.ylim(1, max(y))                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "    plt.scatter(x, y, marker='.')                                                                                                    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deg_frequency(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251238fe",
   "metadata": {},
   "source": [
    "#### Raspodela težinskog stepena čvora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c076414",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deg_frequency(G, weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10) Koliki je prosečni, a koliki globalni koeficijent klasterizacije mreže? \n",
    "# Kakva je raspodela lokalnog koeficijenta klasterizacije njenih čvorova? \n",
    "# Da li je klasterisanje izraženo ili ne? Odgovor dati upoređivanjem sa slučajno generisanom Erdos-Renyi mrežom istih dimenzija. \n",
    "\n",
    "# (Gephi) Average Clustering Coefficient: 0.907\n",
    "# globalni koeficijent klasterizacije mreže ???\n",
    "# raspodela lokalnog koeficijenta klasterizacije ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6027b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da li je klasterisanje izraženo ili ne?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe3ffb",
   "metadata": {},
   "source": [
    "# Mere centralnosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11844bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph(nx.read_gml(\"models/our_model.gml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da152dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_size_list = [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "print(component_size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "S = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "Gdom = G.subgraph(largest_cc).copy()\n",
    "print(f\"Dominantna komponenta ima {len(Gdom.nodes())} čvorova i {len(Gdom.edges())} grana\")\n",
    "nx.write_gml(Gdom, \"models/gdom_model.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_centrality(measure_name, graph):\n",
    "    if measure_name == 'DC':\n",
    "        cm_dict = nx.degree_centrality(graph)\n",
    "    if measure_name == 'CC':\n",
    "        cm_dict = nx.closeness_centrality(graph)\n",
    "    if measure_name == 'BC':\n",
    "        cm_dict = nx.betweenness_centrality(graph)\n",
    "    if measure_name == 'EC':\n",
    "        cm_dict = nx.eigenvector_centrality(graph, weight='weight')\n",
    "\n",
    "    df_cm = pd.DataFrame.from_dict(cm_dict, orient='index', columns=[measure_name])\n",
    "    df_cm = pd.DataFrame({measure_name:df_cm[measure_name]})\n",
    "    df_cm.sort_values(by=measure_name, ascending=False, inplace = True)\n",
    "\n",
    "    print(df_cm.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf384fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_centrality('DC', Gdom)\n",
    "measure_centrality('CC', Gdom)\n",
    "measure_centrality('BC', Gdom)\n",
    "measure_centrality('EC', Gdom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = sorted(Gdom.degree(weight='weight'), key=lambda x:x[1], reverse = True)\n",
    "df_degree = pd.DataFrame.from_dict(dict(degrees), orient='index', columns=['degree'])\n",
    "print(df_degree.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_max =  max(nx.adjacency_spectrum(Gdom))\n",
    "print(lambda_max)\n",
    "print(1/lambda_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [0.000005, 0.000004, 0.000003, 0.000002, 0.000001]\n",
    "\n",
    "for a in alpha_values:\n",
    "    KC_dict = nx.katz_centrality(Gdom, alpha=a, beta=1.0, max_iter=1000, tol=1e-06, nstart=None, normalized=True, weight='weight')\n",
    "    df_katzc = pd.DataFrame.from_dict(KC_dict, orient='index', columns=['KC'])\n",
    "    df_katzc.sort_values(by='KC', ascending=False, inplace = True)\n",
    "    print(df_katzc.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dded1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_list = list(Gdom.nodes)\n",
    "beta_values = [1] * len(nodes_list)\n",
    "\n",
    "vip_subreddit = unique_subreddits[unique_subreddits['subreddit'] == 'reddit.com']\n",
    "vip_index = nodes_list.index(vip_subreddit['subreddit_id'].item())\n",
    "beta_values[vip_index] = 10\n",
    "\n",
    "beta_dict = dict(zip(nodes_list, beta_values))\n",
    "\n",
    "for a in alpha_values:\n",
    "    KC_dict = nx.katz_centrality(Gdom, alpha=a, beta=beta_dict, max_iter=1000, tol=1e-06, nstart=None, normalized=True, weight='weight')\n",
    "    df_katzc = pd.DataFrame.from_dict(KC_dict, orient='index', columns=['KC'])\n",
    "    df_katzc.sort_values(by='KC', ascending=False, inplace = True)\n",
    "    print(df_katzc.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8d3c2",
   "metadata": {},
   "source": [
    "# Komune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatterplot(x_data, y_data, x_label, y_label, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x_data, y_data) \n",
    "    ax.set_ylabel(y_label, fontsize=15)\n",
    "    ax.set_xlabel(x_label, fontsize=15)\n",
    "    ax.set_title(title)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c28afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_dom = nx.laplacian_matrix(Gdom).toarray()\n",
    "\n",
    "eigenvalues = linalg.eigvals(L_dom) # TODO: change to .eigenvalsh because we know the matrix is symmetric\n",
    "eigenvalues.sort()\n",
    "enumerator = np.array(range(1, len(eigenvalues)+1))\n",
    "df_eig = pd.DataFrame(list(zip(enumerator, eigenvalues)))\n",
    "\n",
    "# write eigenvalue table\n",
    "df_eig30 = df_eig[:60]\n",
    "df_eig30.columns = ['k', 'lambda_k']\n",
    "df_eig30 = df_eig30.astype({'k': 'int32', 'lambda_k':'float'})\n",
    "print(df_eig30)\n",
    "\n",
    "plot_scatterplot(enumerator, eigenvalues, r'$k$', r'$\\lambda_k$', 'Ceo spektar graf laplasijana dominantne komponente')\n",
    "\n",
    "df_eig_30 = df_eig[:30]\n",
    "plot_scatterplot(df_eig_30.iloc[:,0], df_eig_30.iloc[:,1], r'$k$', r'$\\lambda_k$', 'Prvih 30 sopstvenih vrednosti graf laplasijana dom. komponente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6183b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_of_interest = [2, 3, 5, 8, 12, 14, 17]\n",
    "\n",
    "for k in points_of_interest:\n",
    "    \n",
    "    clustering = SpectralClustering(n_clusters=k,\n",
    "    assign_labels=\"discretize\", affinity=\"precomputed\").fit(nx.adjacency_matrix(Gdom))\n",
    "\n",
    "    colors = clustering.labels_\n",
    "    c_string = []\n",
    "    for c in colors:\n",
    "        c_string.append(str(c))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for c, label in zip(c_string, Gdom.nodes()):\n",
    "        G.add_node(label, color=c)\n",
    "\n",
    "    for edge in Gdom.edges(data=True):\n",
    "        #print(edge)\n",
    "        G.add_edge(edge[0], edge[1], weight=edge[2]['weight'])\n",
    "\n",
    "    # nx.write_pajek(G, \"etf/spectral3.net\")\n",
    "    nx.write_gml(G, f\"models/spectral{k}.gml\")\n",
    "    \n",
    "    csizes = np.zeros(shape=k, dtype=int)\n",
    "    for c in colors:\n",
    "        csizes[int(c)] += 1\n",
    "    \n",
    "    print(f\"Podela na {k}: velicine komponenata su {csizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78895d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "Gcom = nx.Graph(nx.read_gml(f\"models/spectral{k}.gml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c11cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_ids = [None] * k\n",
    "\n",
    "for i in range(k):\n",
    "    com_ids[i] = []\n",
    "\n",
    "for n, prop in Gcom.nodes(data=True):\n",
    "    com_ids[int(prop['color'])].append(n)\n",
    "    \n",
    "for l in com_ids:\n",
    "    print(\"\\n\")\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf50239",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_subred = unique_subreddits[unique_subreddits['subreddit_id'].isin(com_ids[1])]\n",
    "print(color_subred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiG = nx.DiGraph()\n",
    "\n",
    "DiG.add_nodes_from([1, 2])\n",
    "DiG.add_edge(1, 2)\n",
    "DiG.add_edge(1, 2)\n",
    "DiG.add_edge(2, 1)\n",
    "DiG.edges[1, 2]['weight'] = 2;\n",
    "\n",
    "nx.write_gml(DiG, \"models/test.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd0b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
